{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_r4UUCGMTYac",
        "outputId": "ceb295aa-f5cb-48ce-d194-5322d319461d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m32.8/32.8 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m817.7/817.7 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m312.3/312.3 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.1/8.1 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m902.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m299.3/299.3 kB\u001b[0m \u001b[31m788.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m116.4/116.4 kB\u001b[0m \u001b[31m959.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m83.0/83.0 kB\u001b[0m \u001b[31m648.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m601.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m500.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m473.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m556.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m573.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m668.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1QTyYcpIJuw",
        "outputId": "6060c0f3-621e-43ba-823d-676256cb406a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "\n",
        "import os\n",
        "import re\n",
        "import streamlit as st\n",
        "import transformers\n",
        "from transformers import pipeline\n",
        "from transformers import AutoTokenizer\n",
        "import nltk\n",
        "from PIL import Image\n",
        "import torch\n",
        "import ffmpeg\n",
        "import speech_recognition as sr\n",
        "from pytube import YouTube\n",
        "import string\n",
        "import whisper\n",
        "from moviepy.editor import AudioFileClip\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.memory import ConversationBufferWindowMemory\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.callbacks import get_openai_callback\n",
        "from key import openai_api_key\n",
        "from langchain import PromptTemplate\n",
        "from langchain import LLMChain\n",
        "os.environ['OPENAI_API_KEY'] = openai_api_key\n",
        "\n",
        "\n",
        "  # Criando a funÃ§Ã£o que corta o texto em chunks:\n",
        "def get_chunks(texto_transcrito):\n",
        "    \"\"\"FunÃ§Ã£o que recebe uma string (um texto transcrito) e devolve\n",
        "    uma lista de strings, em que cada string (\"chunk\") contÃ©m um\n",
        "    tamanho especÃ­fico, com overlap entre os pedaÃ§os. \"\"\"\n",
        "    text_splitter=CharacterTextSplitter(separator='.', chunk_size=1000, chunk_overlap=100, length_function=len)\n",
        "    chunks = text_splitter.split_text(texto_transcrito)\n",
        "    return chunks\n",
        "\n",
        "  # Criando a funÃ§Ã£o de vectorstore para transformar os chunks de texto em embeddings:\n",
        "def get_vectorstore(chunks):\n",
        "    \"\"\"FunÃ§Ã£o que recebe uma lista de chunks de texto e\n",
        "    os converte em embeddings (representaÃ§Ãµes numÃ©ricas)\n",
        "    usando um modelo de embeddings prÃ©-treinado. \"\"\"\n",
        "    embeddings = OpenAIEmbeddings()\n",
        "    vectorstore = FAISS.from_texts(texts=chunks, embedding=embeddings)\n",
        "    return vectorstore\n",
        "\n",
        "\n",
        "  # Criando a funÃ§Ã£o para converter o vÃ­deo para o formato adequado:\n",
        "@st.cache_data\n",
        "def convert_mp4_to_wav(mp4_file, wav_file):\n",
        "    \"\"\"FunÃ§Ã£o que converte um arquivo de vÃ­deo no formato MP4 para um arquivo de\n",
        "    Ã¡udio no formato WAV a partir das seguintes entradas: o caminho do arquivo\n",
        "    de vÃ­deo no formato MP4 que se deseja converter; o caminho onde o arquivo\n",
        "    de Ã¡udio WAV resultante serÃ¡ salvo. Nenhuma saÃ­da explÃ­cita Ã© retornada.\"\"\"\n",
        "    video = AudioFileClip(mp4_file)\n",
        "    video.write_audiofile(wav_file)\n",
        "\n",
        "  # Criando a funÃ§Ã£o que gera a transcriÃ§Ã£o:\n",
        "@st.cache_data\n",
        "def get_transcriptions(url):\n",
        "    \"\"\" FunÃ§Ã£o que recebe um link de um vÃ­deo no YouTube e\n",
        "    devolve um dicionÃ¡rio contendo o tÃ­tulo do vÃ­deo (key)\n",
        "    e a transcriÃ§Ã£o de seu Ã¡udio (value). \"\"\"\n",
        "    dicionario = {}\n",
        "      # Baixando o Ã¡udio:\n",
        "    youtube_content = YouTube(url)\n",
        "    audio_streams = youtube_content.streams.filter(only_audio=True)\n",
        "    audio_streams[0].download()\n",
        "    title = youtube_content.title\n",
        "      # Convertendo para Wav:\n",
        "    mp4_file = '/content/'+''.join(char for char in title if char not in string.punctuation.replace('/', '').replace('-', '').replace('!', '').replace('(', '').replace(')', ''))+'.mp4'\n",
        "    wav_file = '/content/'+''.join(char for char in title if char not in string.punctuation.replace('/', '').replace('-', '').replace('!', '').replace('(', '').replace(')', ''))+'.wav'\n",
        "    convert_mp4_to_wav(mp4_file, wav_file)\n",
        "      # Inicializando o reconhecedor de fala:\n",
        "    r = sr.Recognizer()\n",
        "      # Carregando o Ã¡udio gravado pelo Whisper em um objeto de Ã¡udio:\n",
        "    with sr.AudioFile(wav_file) as source:\n",
        "        audio = r.record(source)\n",
        "      # Transcrevendo:\n",
        "    texto_transcrito = r.recognize_whisper(audio)\n",
        "      # Adicionando ao dicionario:\n",
        "    dicionario[title] = texto_transcrito\n",
        "    return dicionario\n",
        "\n",
        "\n",
        "  # Criando a funÃ§Ã£o que carrega o sumarizador extrativo (para portuguÃªs e inglÃªs) via HuggingFace:\n",
        "@st.cache_resource\n",
        "def load_extractive():\n",
        "    \"\"\" FunÃ§Ã£o sem valores de entrada que carrega o modelo\n",
        "     de sumarizaÃ§Ã£o extrativa via HuggingFace. \"\"\"\n",
        "    return pipeline(\"summarization\", model=\"NotXia/longformer-bio-ext-summ\", tokenizer=AutoTokenizer.from_pretrained(\"NotXia/longformer-bio-ext-summ\"), trust_remote_code=True)\n",
        "\n",
        "  # Criando a funÃ§Ã£o que gera a sumarizaÃ§Ã£o extrativa:\n",
        "@st.cache_data\n",
        "def get_summarization(_model_pipeline, full_text, ratio):\n",
        "    \"\"\" FunÃ§Ã£o que recebe um texto completo a ser resumido, juntamente\n",
        "    Ã  taxa desejada de sumarizaÃ§Ã£o e a pipeline do modelo que farÃ¡ o\n",
        "    sumÃ¡rio, e devolve a versÃ£o resumida desse texto. \"\"\"\n",
        "    sentences = nltk.sent_tokenize(full_text)\n",
        "    extractive_sentences = _model_pipeline({\"sentences\": sentences}, strategy=\"ratio\", strategy_args=ratio)\n",
        "    extractive_text = \" \".join(extractive_sentences[0])\n",
        "    return extractive_text\n",
        "\n",
        "\n",
        "  # Criando a funÃ§Ã£o que gera a traduÃ§Ã£o do texto a partir do ChatGPT:\n",
        "@st.cache_data\n",
        "def get_translation(summarized_text):\n",
        "    \"\"\" FunÃ§Ã£o que recebe um resumo a ser traduzido,\n",
        "    juntamente Ã  pipeline do modelo que farÃ¡ a traduÃ§Ã£o,\n",
        "    e devolve a versÃ£o traduzida do texto. \"\"\"\n",
        "    LLM = ChatOpenAI(openai_api_key=openai_api_key, temperature=0.25, model_name=\"gpt-3.5-turbo\")\n",
        "    messages = [SystemMessage(content='VocÃª Ã© um especialista em traduÃ§Ãµes de texto do inglÃªs para portuguÃªs'), HumanMessage(content=summarized_text)]\n",
        "    translation = LLM(messages)\n",
        "    return translation.content\n",
        "\n",
        "\n",
        "  # Criando a funÃ§Ã£o que corrige os erros de transcriÃ§Ã£o do texto a partir do ChatGPT:\n",
        "@st.cache_data\n",
        "def get_correction(transcription):\n",
        "    \"\"\" FunÃ§Ã£o que recebe a transcriÃ§Ã£o (em PT-BR) e corrige eventuais\n",
        "    erros do whisper - por exemplo, a troca de palavras que, embora\n",
        "    semelhantes na pronÃºncia, sÃ£o totalmente absurdas no contexto. \"\"\"\n",
        "    correction_prompt = PromptTemplate.from_template(template = 'VocÃª Ã© um especialista em correÃ§Ã£o de textos. VocÃª receberÃ¡ uma transcriÃ§Ã£o de um Ã¡udio e deverÃ¡ substituir as palavras transcritas erroneamente, considerando apenas a pronÃºncia, por palavras adequadas que faÃ§am sentido no contexto do texto. AlÃ©m disso, corrija questÃµes gramÃ¡ticais para facilitar a compreensÃ£o. Corrija a seguinte transcriÃ§Ã£o: {transcription}')\n",
        "    LLM = ChatOpenAI(openai_api_key=openai_api_key, temperature=0.1, model_name=\"gpt-3.5-turbo\")\n",
        "    corrector = LLMChain(prompt=correction_prompt, llm=LLM)\n",
        "    with get_openai_callback() as cb:\n",
        "        corrected_transcription = corrector.run({\"transcription\": transcription})\n",
        "        total_t = cb.total_tokens\n",
        "        prompt_t = cb.prompt_tokens\n",
        "        completion_t = cb.completion_tokens\n",
        "        total_cost = cb.total_cost\n",
        "    return corrected_transcription\n",
        "\n",
        "\n",
        "  # Criando o chatbot\n",
        "def alan_videos(vectorstore):\n",
        "    \"\"\" FunÃ§Ã£o que inicializa e configura um LLM da OpenAI\n",
        "    e retorna um chatbot configurado pronto para uso. \"\"\"\n",
        "    memory = ConversationBufferWindowMemory(memory_key='chat_history', return_messages=True, k=3)\n",
        "    LLM = ChatOpenAI(openai_api_key=openai_api_key, temperature=0.25, model_name=\"gpt-3.5-turbo\")\n",
        "    retriever=vectorstore.as_retriever()\n",
        "    chatbot = ConversationalRetrievalChain.from_llm(llm=LLM, retriever=retriever, memory=memory)\n",
        "    return chatbot\n",
        "\n",
        "  # Criando um modelo de chat:\n",
        "def chat(pergunta):\n",
        "    \"\"\" FunÃ§Ã£o que processa uma pergunta utilizando o chatbot\n",
        "    configurado (alan_videos) e retorna sua resposta. \"\"\"\n",
        "    with get_openai_callback() as cb:\n",
        "        resposta = st.session_state.alanvideos.invoke({\"question\": pergunta})\n",
        "        total_t = cb.total_tokens\n",
        "        prompt_t = cb.prompt_tokens\n",
        "        completion_t = cb.completion_tokens\n",
        "        total_cost = cb.total_cost\n",
        "    return resposta['answer']\n",
        "\n",
        "\n",
        "  # Criando a funÃ§Ã£o para customizaÃ§Ã£o com CSS:\n",
        "def local_css(file_name):\n",
        "    \"\"\" FunÃ§Ã£o que carrega um arquivo CSS local e aplica o estilo\n",
        "    ao Streamlit app, personalizando a interface do usuÃ¡rio. \"\"\"\n",
        "    with open(file_name, \"r\") as f:\n",
        "        st.markdown(f\"<style>{f.read()}</style>\", unsafe_allow_html=True)\n",
        "\n",
        "  # Configurando a aba do site:\n",
        "icon = Image.open(\"TraÃ§ado laranja #f1863d.png\")\n",
        "st.set_page_config(page_title=\"AlanVideos\", page_icon=icon, layout=\"wide\", initial_sidebar_state=\"auto\")\n",
        "\n",
        "\n",
        "  # Configurando o site:\n",
        "def main():\n",
        "    local_css(\"style.css\")\n",
        "\n",
        "    header = st.container()\n",
        "    model = st.container()\n",
        "    model_1 = st.container()\n",
        "    model_2 = st.container()\n",
        "\n",
        "      # Configurando a barra lateral:\n",
        "    with st.sidebar:\n",
        "        with st.form(\"data_collection\"):\n",
        "            link = st.text_area(label=\"Coloque o link do seu vÃ­deo do YouTube:\", height=25, placeholder=\"Digite seu link...\")\n",
        "            language = st.selectbox('Qual a linguagem do seu vÃ­deo?', ('PortuguÃªs (pt)', 'InglÃªs (en)'))\n",
        "            translate = st.selectbox('VocÃª deseja que o seu vÃ­deo seja traduzido para PortuguÃªs?', ('NÃ£o', 'Sim'))\n",
        "            compression_rate = st.slider(label=\"Selecione o percentual de sumarizaÃ§Ã£o:\", min_value=0.05, max_value=0.50, value=0.25, step=0.05)\n",
        "            submitted = st.form_submit_button(\"Enviar\")\n",
        "\n",
        "            # Verificando se o link do vÃ­deo Ã© vÃ¡lido:\n",
        "            if link != '':\n",
        "                if re.match((r'(https?://)?(www\\.)?''(youtube|youtu|youtube-nocookie)\\.(com|be)/''(watch\\?v=|embed/|v/|.+\\?v=)?([^&=%\\?]{11})'), link):\n",
        "                    st.success('Dados coletados!', icon=\"âœ…\")\n",
        "                else:\n",
        "                    st.error('Link invÃ¡lido. Por favor, insira um link do YouTube.', icon=\"ğŸš¨\")\n",
        "\n",
        "    if \"alanvideos\" not in st.session_state:\n",
        "        st.session_state.alanvideos = None\n",
        "\n",
        "      # Configurando o cabeÃ§alho:\n",
        "    with header:\n",
        "        st.title(\":orange[Alan]Chat\")\n",
        "        st.subheader(\"OlÃ¡, usuÃ¡rio! Este Ã© um projeto que utiliza tÃ©cnicas de inteligÃªncia artificial para simplificar e acelerar a compreensÃ£o de conteÃºdo audiovisual. Por favor, preencha o formulÃ¡rio ao lado para que possamos responder as suas dÃºvidas a respeito de um vÃ­deo do YouTube!  :)\", divider = \"orange\")\n",
        "\n",
        "      # Configurando os modelos:\n",
        "    with model:\n",
        "        if submitted and re.match((r'(https?://)?(www\\.)?''(youtube|youtu|youtube-nocookie)\\.(com|be)/''(watch\\?v=|embed/|v/|.+\\?v=)?([^&=%\\?]{11})'), link):\n",
        "            with st.spinner(\"Carregando modelos...\"):\n",
        "                nltk.download(\"punkt\")\n",
        "                extractive = load_extractive()\n",
        "            with st.spinner(\"Transcrevendo texto...\"):\n",
        "                transcription = get_transcriptions(link)\n",
        "                texto_cru = ''.join(list(transcription.values()))\n",
        "              # Preparando o modelo de sumarizaÃ§Ã£o apÃ³s o envio de um link:\n",
        "            with model_1:\n",
        "                st.header(\"Texto Sumarizado:\")\n",
        "                with st.spinner(\"Carregando sumarizaÃ§Ã£o...\"):\n",
        "                    summary = get_summarization(extractive, texto_cru, compression_rate)\n",
        "                      # Usando o GPT para corrigir a transcriÃ§Ã£o, caso o vÃ­deo seja em PT-BR:\n",
        "                    if language == 'PortuguÃªs (pt)':\n",
        "                        summary = get_correction(summary)\n",
        "                      # Usando o GPT para traduzir a transcriÃ§Ã£o para PT-BR, caso o usuÃ¡rio prefira:\n",
        "                    elif language == 'InglÃªs (en)' and translate == 'Sim':\n",
        "                        with st.spinner(\"Traduzindo sumarizaÃ§Ã£o...\"):\n",
        "                            summary = get_translation(summary)\n",
        "                    st.session_state['summary'] = summary\n",
        "              # Preparando o AlanVideos apÃ³s o envio de um link:\n",
        "            with model_2:\n",
        "                st.header(\"Resposta das perguntas:\")\n",
        "                with st.spinner(\"Preparando AlanVideoss...\"):\n",
        "                      # Separando o texto em chunks:\n",
        "                    chunks = get_chunks(texto_cru)\n",
        "                      # Armazenando os pedaÃ§os de texto em embeddings:\n",
        "                    vectorstore = get_vectorstore(chunks)\n",
        "                      # Criando o chatbot:\n",
        "                    st.session_state.alanvideos = alan_videos(vectorstore)\n",
        "\n",
        "      # Apresentando os resultados:\n",
        "    with model:\n",
        "          # Resultado do modelo de sumarizaÃ§Ã£o:\n",
        "        with model_1:\n",
        "            if 'summary' in st.session_state:\n",
        "                st.write(st.session_state['summary'])\n",
        "      # Resultado do AlanVideos:\n",
        "    if 'summary' in st.session_state:\n",
        "        if \"chat_history\" not in st.session_state:\n",
        "            st.session_state.chat_history = [AIMessage(content=f\"OlÃ¡, meu nome Ã© Alan, e estou aqui para responder perguntas sobre o vÃ­deo. Como posso ajudar?\")]\n",
        "        pergunta = st.chat_input('FaÃ§a uma pergunta sobre o vÃ­deo: ')\n",
        "        if pergunta is not None and pergunta != \"\":\n",
        "            resposta = chat(pergunta)\n",
        "            st.session_state.chat_history.append(HumanMessage(content=pergunta))\n",
        "            st.session_state.chat_history.append(AIMessage(content=resposta))\n",
        "        for message in st.session_state.chat_history:\n",
        "            if isinstance(message, AIMessage):\n",
        "                with st.chat_message(\"AI\"):\n",
        "                    st.write(message.content)\n",
        "            elif isinstance(message, HumanMessage):\n",
        "                with st.chat_message(\"Human\"):\n",
        "                    st.write(message.content)\n",
        "\n",
        "main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPfm2EHyimcF",
        "outputId": "80127d2b-8c4a-4475-bac9-a682fe37ff24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.136.19.61\n"
          ]
        }
      ],
      "source": [
        "!wget -q -O - ipv4.icanhazip.com"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmF1j2csipF8",
        "outputId": "2bc0bbbb-b2f6-4e4b-8e32-5423790888ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.136.19.61:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[K\u001b[?25hnpx: installed 22 in 3.639s\n",
            "your url is: https://tangy-heads-feel.loca.lt\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!streamlit run app.py & npx localtunnel --port 8501"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "ETBAYQ66Heo-",
        "h2eI6F54GrDY"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
