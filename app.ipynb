{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_r4UUCGMTYac",
        "outputId": "ceb295aa-f5cb-48ce-d194-5322d319461d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.8/32.8 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m817.7/817.7 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.3/312.3 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.1/8.1 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m902.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.3/299.3 kB\u001b[0m \u001b[31m788.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.4/116.4 kB\u001b[0m \u001b[31m959.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.0/83.0 kB\u001b[0m \u001b[31m648.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m601.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m500.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m473.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m556.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m573.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m668.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1QTyYcpIJuw",
        "outputId": "6060c0f3-621e-43ba-823d-676256cb406a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "\n",
        "import os\n",
        "import re\n",
        "import streamlit as st\n",
        "import transformers\n",
        "from transformers import pipeline\n",
        "from transformers import AutoTokenizer\n",
        "import nltk\n",
        "from PIL import Image\n",
        "import torch\n",
        "import ffmpeg\n",
        "import speech_recognition as sr\n",
        "from pytube import YouTube\n",
        "import string\n",
        "import whisper\n",
        "from moviepy.editor import AudioFileClip\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.memory import ConversationBufferWindowMemory\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.callbacks import get_openai_callback\n",
        "from key import openai_api_key\n",
        "from langchain import PromptTemplate\n",
        "from langchain import LLMChain\n",
        "os.environ['OPENAI_API_KEY'] = openai_api_key\n",
        "\n",
        "\n",
        "  # Criando a função que corta o texto em chunks:\n",
        "def get_chunks(texto_transcrito):\n",
        "    \"\"\"Função que recebe uma string (um texto transcrito) e devolve\n",
        "    uma lista de strings, em que cada string (\"chunk\") contém um\n",
        "    tamanho específico, com overlap entre os pedaços. \"\"\"\n",
        "    text_splitter=CharacterTextSplitter(separator='.', chunk_size=1000, chunk_overlap=100, length_function=len)\n",
        "    chunks = text_splitter.split_text(texto_transcrito)\n",
        "    return chunks\n",
        "\n",
        "  # Criando a função de vectorstore para transformar os chunks de texto em embeddings:\n",
        "def get_vectorstore(chunks):\n",
        "    \"\"\"Função que recebe uma lista de chunks de texto e\n",
        "    os converte em embeddings (representações numéricas)\n",
        "    usando um modelo de embeddings pré-treinado. \"\"\"\n",
        "    embeddings = OpenAIEmbeddings()\n",
        "    vectorstore = FAISS.from_texts(texts=chunks, embedding=embeddings)\n",
        "    return vectorstore\n",
        "\n",
        "\n",
        "  # Criando a função para converter o vídeo para o formato adequado:\n",
        "@st.cache_data\n",
        "def convert_mp4_to_wav(mp4_file, wav_file):\n",
        "    \"\"\"Função que converte um arquivo de vídeo no formato MP4 para um arquivo de\n",
        "    áudio no formato WAV a partir das seguintes entradas: o caminho do arquivo\n",
        "    de vídeo no formato MP4 que se deseja converter; o caminho onde o arquivo\n",
        "    de áudio WAV resultante será salvo. Nenhuma saída explícita é retornada.\"\"\"\n",
        "    video = AudioFileClip(mp4_file)\n",
        "    video.write_audiofile(wav_file)\n",
        "\n",
        "  # Criando a função que gera a transcrição:\n",
        "@st.cache_data\n",
        "def get_transcriptions(url):\n",
        "    \"\"\" Função que recebe um link de um vídeo no YouTube e\n",
        "    devolve um dicionário contendo o título do vídeo (key)\n",
        "    e a transcrição de seu áudio (value). \"\"\"\n",
        "    dicionario = {}\n",
        "      # Baixando o áudio:\n",
        "    youtube_content = YouTube(url)\n",
        "    audio_streams = youtube_content.streams.filter(only_audio=True)\n",
        "    audio_streams[0].download()\n",
        "    title = youtube_content.title\n",
        "      # Convertendo para Wav:\n",
        "    mp4_file = '/content/'+''.join(char for char in title if char not in string.punctuation.replace('/', '').replace('-', '').replace('!', '').replace('(', '').replace(')', ''))+'.mp4'\n",
        "    wav_file = '/content/'+''.join(char for char in title if char not in string.punctuation.replace('/', '').replace('-', '').replace('!', '').replace('(', '').replace(')', ''))+'.wav'\n",
        "    convert_mp4_to_wav(mp4_file, wav_file)\n",
        "      # Inicializando o reconhecedor de fala:\n",
        "    r = sr.Recognizer()\n",
        "      # Carregando o áudio gravado pelo Whisper em um objeto de áudio:\n",
        "    with sr.AudioFile(wav_file) as source:\n",
        "        audio = r.record(source)\n",
        "      # Transcrevendo:\n",
        "    texto_transcrito = r.recognize_whisper(audio)\n",
        "      # Adicionando ao dicionario:\n",
        "    dicionario[title] = texto_transcrito\n",
        "    return dicionario\n",
        "\n",
        "\n",
        "  # Criando a função que carrega o sumarizador extrativo (para português e inglês) via HuggingFace:\n",
        "@st.cache_resource\n",
        "def load_extractive():\n",
        "    \"\"\" Função sem valores de entrada que carrega o modelo\n",
        "     de sumarização extrativa via HuggingFace. \"\"\"\n",
        "    return pipeline(\"summarization\", model=\"NotXia/longformer-bio-ext-summ\", tokenizer=AutoTokenizer.from_pretrained(\"NotXia/longformer-bio-ext-summ\"), trust_remote_code=True)\n",
        "\n",
        "  # Criando a função que gera a sumarização extrativa:\n",
        "@st.cache_data\n",
        "def get_summarization(_model_pipeline, full_text, ratio):\n",
        "    \"\"\" Função que recebe um texto completo a ser resumido, juntamente\n",
        "    à taxa desejada de sumarização e a pipeline do modelo que fará o\n",
        "    sumário, e devolve a versão resumida desse texto. \"\"\"\n",
        "    sentences = nltk.sent_tokenize(full_text)\n",
        "    extractive_sentences = _model_pipeline({\"sentences\": sentences}, strategy=\"ratio\", strategy_args=ratio)\n",
        "    extractive_text = \" \".join(extractive_sentences[0])\n",
        "    return extractive_text\n",
        "\n",
        "\n",
        "  # Criando a função que gera a tradução do texto a partir do ChatGPT:\n",
        "@st.cache_data\n",
        "def get_translation(summarized_text):\n",
        "    \"\"\" Função que recebe um resumo a ser traduzido,\n",
        "    juntamente à pipeline do modelo que fará a tradução,\n",
        "    e devolve a versão traduzida do texto. \"\"\"\n",
        "    LLM = ChatOpenAI(openai_api_key=openai_api_key, temperature=0.25, model_name=\"gpt-3.5-turbo\")\n",
        "    messages = [SystemMessage(content='Você é um especialista em traduções de texto do inglês para português'), HumanMessage(content=summarized_text)]\n",
        "    translation = LLM(messages)\n",
        "    return translation.content\n",
        "\n",
        "\n",
        "  # Criando a função que corrige os erros de transcrição do texto a partir do ChatGPT:\n",
        "@st.cache_data\n",
        "def get_correction(transcription):\n",
        "    \"\"\" Função que recebe a transcrição (em PT-BR) e corrige eventuais\n",
        "    erros do whisper - por exemplo, a troca de palavras que, embora\n",
        "    semelhantes na pronúncia, são totalmente absurdas no contexto. \"\"\"\n",
        "    correction_prompt = PromptTemplate.from_template(template = 'Você é um especialista em correção de textos. Você receberá uma transcrição de um áudio e deverá substituir as palavras transcritas erroneamente, considerando apenas a pronúncia, por palavras adequadas que façam sentido no contexto do texto. Além disso, corrija questões gramáticais para facilitar a compreensão. Corrija a seguinte transcrição: {transcription}')\n",
        "    LLM = ChatOpenAI(openai_api_key=openai_api_key, temperature=0.1, model_name=\"gpt-3.5-turbo\")\n",
        "    corrector = LLMChain(prompt=correction_prompt, llm=LLM)\n",
        "    with get_openai_callback() as cb:\n",
        "        corrected_transcription = corrector.run({\"transcription\": transcription})\n",
        "        total_t = cb.total_tokens\n",
        "        prompt_t = cb.prompt_tokens\n",
        "        completion_t = cb.completion_tokens\n",
        "        total_cost = cb.total_cost\n",
        "    return corrected_transcription\n",
        "\n",
        "\n",
        "  # Criando o chatbot\n",
        "def alan_videos(vectorstore):\n",
        "    \"\"\" Função que inicializa e configura um LLM da OpenAI\n",
        "    e retorna um chatbot configurado pronto para uso. \"\"\"\n",
        "    memory = ConversationBufferWindowMemory(memory_key='chat_history', return_messages=True, k=3)\n",
        "    LLM = ChatOpenAI(openai_api_key=openai_api_key, temperature=0.25, model_name=\"gpt-3.5-turbo\")\n",
        "    retriever=vectorstore.as_retriever()\n",
        "    chatbot = ConversationalRetrievalChain.from_llm(llm=LLM, retriever=retriever, memory=memory)\n",
        "    return chatbot\n",
        "\n",
        "  # Criando um modelo de chat:\n",
        "def chat(pergunta):\n",
        "    \"\"\" Função que processa uma pergunta utilizando o chatbot\n",
        "    configurado (alan_videos) e retorna sua resposta. \"\"\"\n",
        "    with get_openai_callback() as cb:\n",
        "        resposta = st.session_state.alanvideos.invoke({\"question\": pergunta})\n",
        "        total_t = cb.total_tokens\n",
        "        prompt_t = cb.prompt_tokens\n",
        "        completion_t = cb.completion_tokens\n",
        "        total_cost = cb.total_cost\n",
        "    return resposta['answer']\n",
        "\n",
        "\n",
        "  # Criando a função para customização com CSS:\n",
        "def local_css(file_name):\n",
        "    \"\"\" Função que carrega um arquivo CSS local e aplica o estilo\n",
        "    ao Streamlit app, personalizando a interface do usuário. \"\"\"\n",
        "    with open(file_name, \"r\") as f:\n",
        "        st.markdown(f\"<style>{f.read()}</style>\", unsafe_allow_html=True)\n",
        "\n",
        "  # Configurando a aba do site:\n",
        "icon = Image.open(\"Traçado laranja #f1863d.png\")\n",
        "st.set_page_config(page_title=\"AlanVideos\", page_icon=icon, layout=\"wide\", initial_sidebar_state=\"auto\")\n",
        "\n",
        "\n",
        "  # Configurando o site:\n",
        "def main():\n",
        "    local_css(\"style.css\")\n",
        "\n",
        "    header = st.container()\n",
        "    model = st.container()\n",
        "    model_1 = st.container()\n",
        "    model_2 = st.container()\n",
        "\n",
        "      # Configurando a barra lateral:\n",
        "    with st.sidebar:\n",
        "        with st.form(\"data_collection\"):\n",
        "            link = st.text_area(label=\"Coloque o link do seu vídeo do YouTube:\", height=25, placeholder=\"Digite seu link...\")\n",
        "            language = st.selectbox('Qual a linguagem do seu vídeo?', ('Português (pt)', 'Inglês (en)'))\n",
        "            translate = st.selectbox('Você deseja que o seu vídeo seja traduzido para Português?', ('Não', 'Sim'))\n",
        "            compression_rate = st.slider(label=\"Selecione o percentual de sumarização:\", min_value=0.05, max_value=0.50, value=0.25, step=0.05)\n",
        "            submitted = st.form_submit_button(\"Enviar\")\n",
        "\n",
        "            # Verificando se o link do vídeo é válido:\n",
        "            if link != '':\n",
        "                if re.match((r'(https?://)?(www\\.)?''(youtube|youtu|youtube-nocookie)\\.(com|be)/''(watch\\?v=|embed/|v/|.+\\?v=)?([^&=%\\?]{11})'), link):\n",
        "                    st.success('Dados coletados!', icon=\"✅\")\n",
        "                else:\n",
        "                    st.error('Link inválido. Por favor, insira um link do YouTube.', icon=\"🚨\")\n",
        "\n",
        "    if \"alanvideos\" not in st.session_state:\n",
        "        st.session_state.alanvideos = None\n",
        "\n",
        "      # Configurando o cabeçalho:\n",
        "    with header:\n",
        "        st.title(\":orange[Alan]Videos\")\n",
        "        st.subheader(\"Olá, usuário! Este é um projeto que utiliza técnicas de inteligência artificial para simplificar e acelerar a compreensão de conteúdo audiovisual. Por favor, preencha o formulário ao lado para que possamos responder as suas dúvidas a respeito de um vídeo do YouTube!  :)\", divider = \"orange\")\n",
        "\n",
        "      # Configurando os modelos:\n",
        "    with model:\n",
        "        if submitted and re.match((r'(https?://)?(www\\.)?''(youtube|youtu|youtube-nocookie)\\.(com|be)/''(watch\\?v=|embed/|v/|.+\\?v=)?([^&=%\\?]{11})'), link):\n",
        "            with st.spinner(\"Carregando modelos...\"):\n",
        "                nltk.download(\"punkt\")\n",
        "                extractive = load_extractive()\n",
        "            with st.spinner(\"Transcrevendo texto...\"):\n",
        "                transcription = get_transcriptions(link)\n",
        "                texto_cru = ''.join(list(transcription.values()))\n",
        "              # Preparando o modelo de sumarização após o envio de um link:\n",
        "            with model_1:\n",
        "                st.header(\"Texto Sumarizado:\")\n",
        "                with st.spinner(\"Carregando sumarização...\"):\n",
        "                    summary = get_summarization(extractive, texto_cru, compression_rate)\n",
        "                      # Usando o GPT para corrigir a transcrição, caso o vídeo seja em PT-BR:\n",
        "                    if language == 'Português (pt)':\n",
        "                        summary = get_correction(summary)\n",
        "                      # Usando o GPT para traduzir a transcrição para PT-BR, caso o usuário prefira:\n",
        "                    elif language == 'Inglês (en)' and translate == 'Sim':\n",
        "                        with st.spinner(\"Traduzindo sumarização...\"):\n",
        "                            summary = get_translation(summary)\n",
        "                    st.session_state['summary'] = summary\n",
        "              # Preparando o AlanVideos após o envio de um link:\n",
        "            with model_2:\n",
        "                st.header(\"Resposta das perguntas:\")\n",
        "                with st.spinner(\"Preparando AlanVideos...\"):\n",
        "                      # Separando o texto em chunks:\n",
        "                    chunks = get_chunks(texto_cru)\n",
        "                      # Armazenando os pedaços de texto em embeddings:\n",
        "                    vectorstore = get_vectorstore(chunks)\n",
        "                      # Criando o chatbot:\n",
        "                    st.session_state.alanvideos = alan_videos(vectorstore)\n",
        "\n",
        "      # Apresentando os resultados:\n",
        "    with model:\n",
        "          # Resultado do modelo de sumarização:\n",
        "        with model_1:\n",
        "            if 'summary' in st.session_state:\n",
        "                st.write(st.session_state['summary'])\n",
        "      # Resultado do AlanVideos:\n",
        "    if 'summary' in st.session_state:\n",
        "        if \"chat_history\" not in st.session_state:\n",
        "            st.session_state.chat_history = [AIMessage(content=f\"Olá, meu nome é Alan, e estou aqui para responder perguntas sobre o vídeo. Como posso ajudar?\")]\n",
        "        pergunta = st.chat_input('Faça uma pergunta sobre o vídeo: ')\n",
        "        if pergunta is not None and pergunta != \"\":\n",
        "            resposta = chat(pergunta)\n",
        "            st.session_state.chat_history.append(HumanMessage(content=pergunta))\n",
        "            st.session_state.chat_history.append(AIMessage(content=resposta))\n",
        "        for message in st.session_state.chat_history:\n",
        "            if isinstance(message, AIMessage):\n",
        "                with st.chat_message(\"AI\"):\n",
        "                    st.write(message.content)\n",
        "            elif isinstance(message, HumanMessage):\n",
        "                with st.chat_message(\"Human\"):\n",
        "                    st.write(message.content)\n",
        "\n",
        "main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPfm2EHyimcF",
        "outputId": "80127d2b-8c4a-4475-bac9-a682fe37ff24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.136.19.61\n"
          ]
        }
      ],
      "source": [
        "!wget -q -O - ipv4.icanhazip.com"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmF1j2csipF8",
        "outputId": "2bc0bbbb-b2f6-4e4b-8e32-5423790888ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.136.19.61:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[K\u001b[?25hnpx: installed 22 in 3.639s\n",
            "your url is: https://tangy-heads-feel.loca.lt\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!streamlit run app.py & npx localtunnel --port 8501"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "ETBAYQ66Heo-",
        "h2eI6F54GrDY"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
